<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Logistic Regression Â· JuMP</title><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-44252521-1', 'auto');
ga('send', 'pageview', {'page': location.pathname + location.search + location.hash});
</script><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../../assets/documenter.js"></script><script src="../../../siteinfo.js"></script><script src="../../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../../"><img src="../../../assets/logo.png" alt="JuMP logo"/></a><div class="docs-package-name"><span class="docs-autofit">JuMP</span></div><form class="docs-search" action="../../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../../">Introduction</a></li><li><a class="tocitem" href="../../../installation/">Installation Guide</a></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox" checked/><label class="tocitem" for="menuitem-3"><span class="docs-label">Tutorials</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><input class="collapse-toggle" id="menuitem-3-1" type="checkbox"/><label class="tocitem" for="menuitem-3-1"><span class="docs-label">Getting started</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../Getting started/an_introduction_to_julia/">Getting started with Julia</a></li><li><a class="tocitem" href="../../Getting started/getting_started_with_JuMP/">Getting started with JuMP</a></li><li><a class="tocitem" href="../../Getting started/performance_tips/">Performance tips</a></li><li><a class="tocitem" href="../../Getting started/solvers_and_solutions/">Solvers and Solutions</a></li><li><a class="tocitem" href="../../Getting started/variables_constraints_objective/">Variables, constraints, and objective functions</a></li><li><a class="tocitem" href="../../Getting started/working_with_data_files/">Working with Data Files</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-2" type="checkbox"/><label class="tocitem" for="menuitem-3-2"><span class="docs-label">Mixed-integer linear programs</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../Mixed-integer linear programs/callbacks/">Callbacks</a></li><li><a class="tocitem" href="../../Mixed-integer linear programs/cannery/">The cannery problem</a></li><li><a class="tocitem" href="../../Mixed-integer linear programs/cutting_stock_column_generation/">Cutting stock</a></li><li><a class="tocitem" href="../../Mixed-integer linear programs/diet/">The diet problem</a></li><li><a class="tocitem" href="../../Mixed-integer linear programs/factory_schedule/">The factory schedule example</a></li><li><a class="tocitem" href="../../Mixed-integer linear programs/finance/">Finance</a></li><li><a class="tocitem" href="../../Mixed-integer linear programs/geographic_clustering/">Geographical Clustering</a></li><li><a class="tocitem" href="../../Mixed-integer linear programs/knapsack/">The knapsack problem</a></li><li><a class="tocitem" href="../../Mixed-integer linear programs/multi/">The multi-commodity flow problem</a></li><li><a class="tocitem" href="../../Mixed-integer linear programs/n-queens/">N-Queens</a></li><li><a class="tocitem" href="../../Mixed-integer linear programs/network_flows/">Network Flows</a></li><li><a class="tocitem" href="../../Mixed-integer linear programs/power_systems/">Power Systems</a></li><li><a class="tocitem" href="../../Mixed-integer linear programs/prod/">The workforce scheduling problem</a></li><li><a class="tocitem" href="../../Mixed-integer linear programs/steelT3/">The SteelT3 problem</a></li><li><a class="tocitem" href="../../Mixed-integer linear programs/sudoku/">Sudoku</a></li><li><a class="tocitem" href="../../Mixed-integer linear programs/tips_and_tricks/">Tips and tricks</a></li><li><a class="tocitem" href="../../Mixed-integer linear programs/transp/">The transportation problem</a></li><li><a class="tocitem" href="../../Mixed-integer linear programs/urban_plan/">The urban planning problem</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-3" type="checkbox"/><label class="tocitem" for="menuitem-3-3"><span class="docs-label">Nonlinear programs</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../Nonlinear programs/clnlbeam/">The clnlbeam problem</a></li><li><a class="tocitem" href="../../Nonlinear programs/mle/">Maximum likelihood estimation</a></li><li><a class="tocitem" href="../../Nonlinear programs/nlp_tricks/">Nonlinear tips and tricks</a></li><li><a class="tocitem" href="../../Nonlinear programs/rocket_control/">Rocket Control</a></li><li><a class="tocitem" href="../../Nonlinear programs/rosenbrock/">The Rosenbrock function</a></li><li><a class="tocitem" href="../../Nonlinear programs/space_shuttle_reentry_trajectory/">Space Shuttle Reentry Trajectory</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-4" type="checkbox"/><label class="tocitem" for="menuitem-3-4"><span class="docs-label">Quadratic programs</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../Quadratic programs/portfolio/">Portfolio Optimization</a></li><li><a class="tocitem" href="../../Quadratic programs/qcp/">Quadratically constrained programs</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-5" type="checkbox" checked/><label class="tocitem" for="menuitem-3-5"><span class="docs-label">Conic programs</span><i class="docs-chevron"></i></label><ul class="collapsed"><li class="is-active"><a class="tocitem" href>Logistic Regression</a><ul class="internal"><li><a class="tocitem" href="#Formulating-the-logistic-regression-problem"><span>Formulating the logistic regression problem</span></a></li><li><a class="tocitem" href="#Reformulation-as-a-conic-optimization-problem"><span>Reformulation as a conic optimization problem</span></a></li><li><a class="tocitem" href="#Fitting-logistic-regression-with-a-conic-solver"><span>Fitting logistic regression with a conic solver</span></a></li></ul></li><li><a class="tocitem" href="../tips_and_tricks/">Tips and Tricks</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-6" type="checkbox"/><label class="tocitem" for="menuitem-3-6"><span class="docs-label">Semidefinite programs</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../Semidefinite programs/cluster/">K-means clustering via SDP</a></li><li><a class="tocitem" href="../../Semidefinite programs/corr_sdp/">The correlation problem</a></li><li><a class="tocitem" href="../../Semidefinite programs/experiment_design/">Experiment Design</a></li><li><a class="tocitem" href="../../Semidefinite programs/max_cut_sdp/">SDP relaxations: max-cut</a></li><li><a class="tocitem" href="../../Semidefinite programs/min_distortion/">The minimum distortion problem</a></li><li><a class="tocitem" href="../../Semidefinite programs/min_ellipse/">Minimum ellipses</a></li><li><a class="tocitem" href="../../Semidefinite programs/robust_uncertainty/">Robust uncertainty sets</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-7" type="checkbox"/><label class="tocitem" for="menuitem-3-7"><span class="docs-label">Optimization concepts</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../Optimization concepts/benders_decomposition/">Benders Decomposition</a></li><li><a class="tocitem" href="../../Optimization concepts/benders_lazy_constraints/">Benders Decomposition (Lazy Constraints)</a></li></ul></li></ul></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox"/><label class="tocitem" for="menuitem-4"><span class="docs-label">Manual</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../../manual/models/">Models</a></li><li><a class="tocitem" href="../../../manual/variables/">Variables</a></li><li><a class="tocitem" href="../../../manual/expressions/">Expressions</a></li><li><a class="tocitem" href="../../../manual/objective/">Objectives</a></li><li><a class="tocitem" href="../../../manual/constraints/">Constraints</a></li><li><a class="tocitem" href="../../../manual/containers/">Containers</a></li><li><a class="tocitem" href="../../../manual/solutions/">Solutions</a></li><li><a class="tocitem" href="../../../manual/nlp/">Nonlinear Modeling</a></li><li><a class="tocitem" href="../../../manual/callbacks/">Callbacks</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-5" type="checkbox"/><label class="tocitem" for="menuitem-5"><span class="docs-label">API Reference</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../../reference/models/">Models</a></li><li><a class="tocitem" href="../../../reference/variables/">Variables</a></li><li><a class="tocitem" href="../../../reference/expressions/">Expressions</a></li><li><a class="tocitem" href="../../../reference/objectives/">Objectives</a></li><li><a class="tocitem" href="../../../reference/constraints/">Constraints</a></li><li><a class="tocitem" href="../../../reference/containers/">Containers</a></li><li><a class="tocitem" href="../../../reference/solutions/">Solutions</a></li><li><a class="tocitem" href="../../../reference/nlp/">Nonlinear Modeling</a></li><li><a class="tocitem" href="../../../reference/callbacks/">Callbacks</a></li><li><a class="tocitem" href="../../../reference/moi/">MathOptInterface</a></li><li><a class="tocitem" href="../../../reference/extensions/">Extensions</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-6" type="checkbox"/><label class="tocitem" for="menuitem-6"><span class="docs-label">Background information</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../../background/should_i_use/">Should I use JuMP?</a></li><li><a class="tocitem" href="../../../background/algebraic_modeling_languages/">Algebraic modeling languages</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-7" type="checkbox"/><label class="tocitem" for="menuitem-7"><span class="docs-label">Developer Docs</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../../developers/extensions/">Extensions</a></li><li><a class="tocitem" href="../../../developers/style/">Style Guide</a></li><li><a class="tocitem" href="../../../developers/roadmap/">Roadmap</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li><a class="is-disabled">Conic programs</a></li><li class="is-active"><a href>Logistic Regression</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Logistic Regression</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/jump-dev/JuMP.jl/blob/master/docs/src/tutorials/Conic programs/logistic_regression.jl" title="Edit on GitHub"><span class="docs-icon fab">ï</span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Logistic-Regression"><a class="docs-heading-anchor" href="#Logistic-Regression">Logistic Regression</a><a id="Logistic-Regression-1"></a><a class="docs-heading-anchor-permalink" href="#Logistic-Regression" title="Permalink"></a></h1><p><strong>Originally Contributed by</strong>: FranÃ§ois Pacaud</p><p>This tutorial shows how to solve a logistic regression problem with JuMP. Logistic regression is a well known method in machine learning, useful when we want to classify binary variables with the help of a given set of features. To this goal, we find the optimal combination of features maximizing the (log)-likelihood onto a training set. From a modern optimization glance, the resulting problem is convex and differentiable. On a modern optimization glance, it is even conic representable.</p><h2 id="Formulating-the-logistic-regression-problem"><a class="docs-heading-anchor" href="#Formulating-the-logistic-regression-problem">Formulating the logistic regression problem</a><a id="Formulating-the-logistic-regression-problem-1"></a><a class="docs-heading-anchor-permalink" href="#Formulating-the-logistic-regression-problem" title="Permalink"></a></h2><p>Suppose we have a set of training data-point <span>$i = 1, \cdots, n$</span>, where for each <span>$i$</span> we have a vector of features <span>$x_i \in \mathbb{R}^p$</span> and a categorical observation <span>$y_i \in \{-1, 1\}$</span>.</p><p>The log-likelihood is given by</p><p class="math-container">\[l(\theta) = \sum_{i=1}^n \log(\dfrac{1}{1 + \exp(-y_i \theta^\top x_i)})\]</p><p>and the optimal <span>$\theta$</span> minimizes the logistic loss function:</p><p class="math-container">\[\min_{\theta}\; \sum_{i=1}^n \log(1 + \exp(-y_i \theta^\top x_i)).\]</p><p>Most of the time, instead of solving directly the previous optimization problem, we prefer to add a regularization term:</p><p class="math-container">\[\min_{\theta}\; \sum_{i=1}^n \log(1 + \exp(-y_i \theta^\top x_i)) + \lambda \| \theta \|\]</p><p>with <span>$\lambda \in \mathbb{R}_+$</span> a penalty and <span>$\|.\|$</span> a norm function. By adding such a regularization term, we avoid overfitting on the training set and usually achieve a greater score in cross-validation.</p><h2 id="Reformulation-as-a-conic-optimization-problem"><a class="docs-heading-anchor" href="#Reformulation-as-a-conic-optimization-problem">Reformulation as a conic optimization problem</a><a id="Reformulation-as-a-conic-optimization-problem-1"></a><a class="docs-heading-anchor-permalink" href="#Reformulation-as-a-conic-optimization-problem" title="Permalink"></a></h2><p>By introducing auxiliary variables <span>$t_1, \cdots, t_n$</span> and <span>$r$</span>, the optimization problem is equivalent to</p><p class="math-container">\[\begin{aligned}
\min_{t, r, \theta} \;&amp; \sum_{i=1}^n t_i + \lambda r \\
\text{subject to } &amp; \quad t_i \geq \log(1 + \exp(- y_i \theta^\top x_i)) \\
                   &amp; \quad r \geq \|\theta\|
\end{aligned}\]</p><p>Now, the trick is to reformulate the constraints <span>$t_i \geq \log(1 + \exp(- y_i \theta^\top x_i))$</span> with the help of the <em>exponential cone</em></p><p class="math-container">\[K_{exp} = \{ (x, y, z) \in \mathbb{R}^3 : \; y \exp(x / y) \leq z \} .\]</p><p>Indeed, by passing to the exponential, we see that for all <span>$i=1, \cdots, n$</span>, the constraint <span>$t_i \geq \log(1 + \exp(- y_i \theta^\top x_i))$</span> is equivalent to</p><p class="math-container">\[\exp(-t_i) + \exp(u_i - t_i) \leq 1\]</p><p>with <span>$u_i = -y_i \theta^\top x_i$</span>. Then, by adding two auxiliary variables <span>$z_{i1}$</span> and <span>$z_{i2}$</span> such that <span>$z_{i1} \geq \exp(u_i-t_i)$</span> and <span>$z_{i2} \geq \exp(-t_i)$</span>, we get the equivalent formulation</p><p class="math-container">\[\left\{
\begin{aligned}
(u_i -t_i , 1, z_{i1}) &amp; \in  K_{exp}  \\
(-t_i , 1, z_{i2}) &amp; \in  K_{exp}  \\
z_{i1} + z_{i2} &amp; \leq  1
\end{aligned}
\right.\]</p><p>In this setting, the conic version of the logistic regression problems writes out</p><p class="math-container">\[\begin{aligned}
\min_{t, z, r, \theta}&amp;  \; \sum_{i=1}^n t_i + \lambda r \\
\text{subject to } &amp; \quad  (u_i -t_i , 1, z_{i1})  \in  K_{exp}  \\
                   &amp; \quad  (-t_i , 1, z_{i2})  \in  K_{exp}  \\
                   &amp; \quad  z_{i1} + z_{i2}  \leq  1 \\
                   &amp; \quad u_i = -y_i x_i^\top \theta \\
                   &amp; \quad r \geq \|\theta\|
\end{aligned}\]</p><p>and thus encompasses <span>$3n + p + 1$</span> variables and <span>$3n + 1$</span> constraints (<span>$u_i = -y_i \theta^\top x_i$</span> is only a virtual constraint used to clarify the notation). Thus, if <span>$n \gg 1$</span>, we get a large number of variables and constraints.</p><h2 id="Fitting-logistic-regression-with-a-conic-solver"><a class="docs-heading-anchor" href="#Fitting-logistic-regression-with-a-conic-solver">Fitting logistic regression with a conic solver</a><a id="Fitting-logistic-regression-with-a-conic-solver-1"></a><a class="docs-heading-anchor-permalink" href="#Fitting-logistic-regression-with-a-conic-solver" title="Permalink"></a></h2><p>It is now time to pass to the implementation. We choose SCS as a conic solver.</p><pre><code class="language-julia">using JuMP
import Random
import SCS

Random.seed!(2713);</code></pre><p>We start by implementing a function to generate a fake dataset, and where we could tune the correlation between the feature variables. The function is a direct transcription of the one used in <a href="http://fa.bianp.net/blog/2013/numerical-optimizers-for-logistic-regression/">this blog post</a>.</p><pre><code class="language-julia">function generate_dataset(n_samples=100, n_features=10; shift=0.0)
    X = randn(n_samples, n_features)
    w = randn(n_features)
    y = sign.(X * w)
    X .+= 0.8 * randn(n_samples, n_features) # add noise
    X .+= shift # shift the points in the feature space
    X = hcat(X, ones(n_samples, 1))
    return X, y
end</code></pre><pre class="documenter-example-output">generate_dataset (generic function with 3 methods)</pre><p>We write a <code>softplus</code> function to formulate each constraint <span>$t \geq \log(1 + \exp(u))$</span> with two exponential cones.</p><pre><code class="language-julia">function softplus(model, t, u)
    z = @variable(model, [1:2], lower_bound=0.0)
    @constraint(model, sum(z) &lt;= 1.0)
    @constraint(model, [u - t, 1, z[1]] in MOI.ExponentialCone())
    @constraint(model, [-t, 1, z[2]] in MOI.ExponentialCone())
end</code></pre><pre class="documenter-example-output">softplus (generic function with 1 method)</pre><h3 id="\\ell_2-regularized-logistic-regression"><a class="docs-heading-anchor" href="#\\ell_2-regularized-logistic-regression"><span>$\ell_2$</span> regularized logistic regression</a><a id="\\ell_2-regularized-logistic-regression-1"></a><a class="docs-heading-anchor-permalink" href="#\\ell_2-regularized-logistic-regression" title="Permalink"></a></h3><p>Then, with the help of the <code>softplus</code> function, we could write our optimization model. In the <span>$\ell_2$</span> regularization case, the constraint <span>$r \geq \|\theta\|_2$</span> rewrites as a second order cone constraint.</p><pre><code class="language-julia">function build_logit_model(X, y, Î»)
    n, p = size(X)
    model = Model()
    @variable(model, Î¸[1:p])
    @variable(model, t[1:n])
    for i in 1:n
        u = - (X[i, :]&#39; * Î¸) * y[i]
        softplus(model, t[i], u)
    end
    # Add â2 regularization
    @variable(model, 0.0 &lt;= reg)
    @constraint(model, [reg; Î¸] in MOI.SecondOrderCone(p+1))
    # Define objective
    @objective(model, Min, sum(t) + Î» * reg)
    return model
end</code></pre><pre class="documenter-example-output">build_logit_model (generic function with 1 method)</pre><p>We generate the dataset.</p><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>Be careful here, for large n and p SCS could fail to converge!</p></div></div><pre><code class="language-julia">n, p = 200, 10
X, y = generate_dataset(n, p, shift=10.0);

# We could now solve the logistic regression problem
Î» = 10.0
model = build_logit_model(X, y, Î»)
set_optimizer(model, SCS.Optimizer)
JuMP.optimize!(model)</code></pre><pre><code class="language-julia">Î¸â¯ = JuMP.value.(model[:Î¸])</code></pre><pre class="documenter-example-output">11-element Array{Float64,1}:
  0.3202855747667252 
 -0.5571952231349188 
  0.37942941424695803
 -0.18100209814311582
 -0.5383667478418829 
 -0.2889122859702004 
  0.45076922295074123
 -0.07094730174540306
  0.0650150396447445 
  0.4338209870437348 
 -0.09369944242007228</pre><p>It appears that the speed of convergence is not that impacted by the correlation of the dataset, nor by the penalty <span>$\lambda$</span>.</p><h3 id="\\ell_1-regularized-logistic-regression"><a class="docs-heading-anchor" href="#\\ell_1-regularized-logistic-regression"><span>$\ell_1$</span> regularized logistic regression</a><a id="\\ell_1-regularized-logistic-regression-1"></a><a class="docs-heading-anchor-permalink" href="#\\ell_1-regularized-logistic-regression" title="Permalink"></a></h3><p>We now formulate the logistic problem with a <span>$\ell_1$</span> regularization term. The <span>$\ell_1$</span> regularization ensures sparsity in the optimal solution of the resulting optimization problem. Luckily, the <span>$\ell_1$</span> norm is implemented as a set in <code>MathOptInterface</code>. Thus, we could easily formulate the sparse logistic regression problem with the help of a <code>MOI.NormOneCone</code> set.</p><pre><code class="language-julia">function build_sparse_logit_model(X, y, Î»)
    n, p = size(X)
    model = Model()
    @variable(model, Î¸[1:p])
    @variable(model, t[1:n])
    for i in 1:n
        u = - (X[i, :]&#39; * Î¸) * y[i]
        softplus(model, t[i], u)
    end
    # Add â1 regularization
    @variable(model, 0.0 &lt;= reg)
    @constraint(model, [reg; Î¸] in MOI.NormOneCone(p+1))
    # Define objective
    @objective(model, Min, sum(t) + Î» * reg)
    return model
end

# Auxiliary function to count non-null components:
count_nonzero(v::Vector; tol=1e-6) = sum(abs.(v) .&gt;= tol)

# We solve the sparse logistic regression problem on the same dataset as before.
Î» = 10.0
sparse_model = build_sparse_logit_model(X, y, Î»)
set_optimizer(sparse_model, SCS.Optimizer)
JuMP.optimize!(sparse_model)</code></pre><pre><code class="language-julia">Î¸â¯ = JuMP.value.(sparse_model[:Î¸])
println(&quot;Number of non-zero components: &quot;, count_nonzero(Î¸â¯),
        &quot; (out of &quot;, p, &quot; features)&quot;)</code></pre><pre class="documenter-example-output">Number of non-zero components: 8 (out of 10 features)</pre><h3 id="Extensions"><a class="docs-heading-anchor" href="#Extensions">Extensions</a><a id="Extensions-1"></a><a class="docs-heading-anchor-permalink" href="#Extensions" title="Permalink"></a></h3><p>A direct extension would be to consider the sparse logistic regression with <em>hard</em> thresholding, which, on contrary to the <em>soft</em> version using a <span>$\ell_1$</span> regularization, adds an explicit cardinality constraint in its formulation:</p><p class="math-container">\[\begin{aligned}
\min_{\theta} &amp; \; \sum_{i=1}^n \log(1 + \exp(-y_i \theta^\top x_i)) + \lambda \| \theta \|_2^2 \\
\text{subject to } &amp; \quad \| \theta \|_0 &lt;= k
\end{aligned}\]</p><p>where <span>$k$</span> is the maximum number of non-zero components in the vector <span>$\theta$</span>, and <span>$\|.\|_0$</span> is the <span>$\ell_0$</span> pseudo-norm:</p><p class="math-container">\[\| x\|_0 = \#\{i : \; x_i \neq 0\}\]</p><p>The cardinality constraint <span>$\|\theta\|_0 \leq k$</span> could be reformulated with binary variables. Thus the hard sparse regression problem could be solved by any solver supporting mixed integer conic problems.</p><p><a href="https://github.com/jump-dev/JuMP.jl/blob/master/docs/src/tutorials/Conic programs/logistic_regression.jl">View this file on Github</a>.</p><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../Quadratic programs/qcp/">Â« Quadratically constrained programs</a><a class="docs-footer-nextpage" href="../tips_and_tricks/">Tips and Tricks Â»</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Saturday 8 May 2021 23:27">Saturday 8 May 2021</span>. Using Julia version 1.0.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
